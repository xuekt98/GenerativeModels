training:
  batch_size: 16
  n_epochs: 200
  n_iters: 50000001

data:
  dataset: "face2comic"
  image_size: 128
  channels: 3
  logit_transform: false

model:
  dim: 64
  # dim_mults: (1, 2, 4, 8)
  dim_mults: !!python/tuple
    - 1
    - 2
    - 4
## 200 steps
  n_steps: 200
  beta_min: 0.0001
  beta_max: 0.0095

## 100 steps
#  n_steps: 100
#  beta_min: 0.0001
#  beta_max: 0.0150

## 500 steps
#  n_steps: 500
#  beta_min: 0.0001
#  beta_max: 0.0050

optimizer:
  weight_decay: 0.000
  optimizer: 'Adam'
  lr: 0.001
  beta1: 0.9